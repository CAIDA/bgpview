# BGPView

BGPView is a set of highly optimized data structures and libraries for
(re-)construction, transport and analysis of BGP "routing tables".

## Background

For a detailed description of BGPView, see Section 6.2 of the
[BGPStream paper](https://www.caida.org/publications/papers/2016/bgpstream/bgpstream.pdf).

At a high level, the goal of BGPView is to facilitate the inference of
"Global" routing tables at a finer granularity than the RIB dumps
provided by the RouteViews and RIPE RIS projects. For example,
currently RouteViews collectors export a snapshot of their RIB (a "RIB
dump") every 2 hours -- for RIPE RIS this is once every 8 hours. For
applications where latency matters (e.g., near-realtime event
detection), and/or are interested in observing short-duration events,
they cannot rely on these RIB dumps alone (i.e., using RouteViews
data, they would only be able to observe events that last at least 2
hours, and with up to 2 hours of latency).

The normal approach to solving this problem is to write some code that
starts with a RIB dump, and then incrementally applies update
information to approximate the state of each peer's routing table at
any point in time. Then, depending on the application, one can either
react to specific events (e.g., a prefix is announced, withdrawn,
etc.) or, periodically walk through these routing tables and perform
analysis on the entire "global" routing table (or, "inferred"
RIB). BGPView is designed to make it simple to write analysis code in
the latter model, with all of the details of obtaining the raw BGP
data, processing it, and inferring the routing table for each peer are
abstracted away from the user. The user is instead able to focus on
writing an analysis kernel (a "BGPView Consumer") that is invoked
every time a new inferred RIB (a "BGPView") is available.

There are two primary modes of operation for BGPView: realtime, and
offline.

In realtime mode, there is a set of distributed processes that:
 - obtain the BGP data (using
   [BGPStream](https://bgpstream.caida.org)) as soon as it is made
   available by the upstream projects
 - process it, and
 - periodically (every 5 min in CAIDA's reference deployment) publish
   fragments of each view to a Kafka cluster.
Users can then connect their analysis modules to this cluster using
the BGPView toolset, and as soon as a view becomes available, their
code will analyze it.

In offline mode the BGPView components are similar, but rather than a
distributed set of many processes that communicate via Kafka,
everything runs within a single process. The views that are generated
are passed in-memory to the configured consumers. While this is a
convenient method for using the same analysis code (consumers) to do
longitudinal analysis, it does require significant memory (often >20
GB when using all collectors), and is not a parallelized application,
so processing times are roughly the sum of all components that operate
in the realtime pipeline (whereas, in realtime these components are
truly pipelined).

## Quick Start

### Debian/Ubuntu Packages

The easiest way to install BGPView and its dependencies is from
CAIDA's apt package mirror.

```
curl https://pkg.caida.org/os/ubuntu/boostrap.sh | bash
sudo apt install bgpview
```
Of course you should first manually inspect the `bootstrap.sh` script
before executing it.

### Building From Source

You will need to first install dependencies:

 - [libbgpstream (>= v2.0.0)](https://bgpstream.caida.org)
 - [libtimeseries (>= v1.0.0)](https://github.com/CAIDA/libtimeseries)
 - [libipmeta (>= v3.0.0)](https://github.com/CAIDA/libipmeta)
 - [libwandio (>= v4.2.0)](https://research.wand.net.nz/software/libwandio.php)
 - [librdkafka (>= v0.11.3)](https://github.com/edenhill/librdkafka)

On Ubuntu/Debian systems, this means something like
```
sudo apt install libbgpstream2-dev libtimeseries0-dev \
  libipmeta2-dev libwandio1-dev librdkafka-dev
```
This assumes you have added the CAIDA package archive to apt using the
bootstrap command above.

One you have installed the dependencies, download the BGPView source,
either from the
[GitHub releases page](https://github.com/CAIDA/bgpview/releases), or
by cloning the GitHub repo.

If you cloned from GitHub, you will first need to:
```
./autogen.sh
```

Then:
```
./configure
make
sudo make install
```

This will install the `bgpview-consumer` tool which is used to run the
consumers against a source of BGPViews.

There is also a `bvcat` tool that will be installed. This is used to
convert the binary files generated by the `archiver` consumer into
ASCII format.

## Realtime Analysis

### CAIDA's Public BGPView feed

Because running the realtime BGPView system requires significant
compute infrastructure, CAIDA is making its BGPView feed publicly
accessible. Users can install the BGPView software on their local
servers, and then configure the `kafka` interface to consume data from
the CAIDA Kafka cluster.

#### View Publication Timeouts

TODO: describe why we have timeouts, what the trade-offs are, etc.

Available timeouts:
 - 10 min (`-c 600`)
 - 20 min (`-c 1200`)
 - 30 min (`-c 1800`)
 - 40 min (`-c 2400`)
 - 50 min (`-c 3000`)
 - 1 hr (`-c 3600`)
 - 2 hr (`-c 7200`)
 - 4 hr (`-c 14400`)
 - 6 hr (`-c 28800`)

#### Example Usage

```
bgpview-consumer \
  -i "kafka -k bgpview.bgpstream.caida.org:9192 -n bgpview-prod -c 2400" \
  -N 1 \
  -b ascii \
  -c "test"
```

In this example, we configure the `kafka` IO module to:

 - connect to the Kafka cluster running at
   `bgpview.bgpstream.caida.org:9192` (note the non-standard 9192 port
   number).
 - use the `bgpview-prod` "namespace" in this cluster (this is the
   only available namespace so should not be changed)
 - use the 2400-second timeout view stream (see notes above about
   timeouts)
 - process a single view before exiting (`-N `)
 - use the `ascii` backend for writing timeseries statistics
 - run the `test` consumer (see below for how to run other consumers)

This will require a _significant_ amount of memory to run (> 8 GB).

Note that there are quotes around the arguments to the `-i`
option. This is because the `kafka -k ....` sub-command is passed
directly to the kafka module for argument processing. The same is true
when configuring consumers (here we don't pass arguments to the `test`
consumer, so the quotes are not strictly necessary).

To filter the view to a prefix (or origin ASN) of interest, the `-f`
option can be used as follows:
```
bgpview-consumer \
  -i "kafka -k bgpview.bgpstream.caida.org:9192 -n bgpview-prod -c 2400" \
  -N 1 \
  -b ascii \
  -c "test" \
  -f "pfx:192.172.226.0/24"
```

The BGPView code currently outputs a large amount of debugging
information
([Issue #25](https://github.com/CAIDA/bgpview/issues/25)). You may
want to filter it out by doing something like:
```
bgpview-consuer [arguments] 2>&1 | grep -v DEBUG
```

### Running a private BGPView deployment

TODO

## Offline Analysis

### One-off Processing

### Spark-managed Processing

## Available Consumers

All consumer code is located in the
[lib/consumers/](https://github.com/CAIDA/bgpview/tree/master/lib/consumers)
directory. Consumer source files are named `bvc_<consumer>.[ch]`.

To get a list of consumers built into a bgpview-consumer binary, run
it without arguments. To see the usage for a specific consumer, run it
like so:
```
bgpview-consumer -b ascii -i test -c "<CONSUMER> -h"
```
e.g.,
```
$ bgpview-consumer -b ascii -i test -c "archiver -h"
[09:52:52:870] timeseries_init: initializing libtimeseries
[09:52:52:870] timeseries_enable_backend: enabling backend (ascii)
INFO: Enabling consumer 'archiver'
consumer usage: archiver
       -f <filename> output file pattern for writing views
                       accepts same format parameters as strftime(3)
                       as well as '%s' to write unix time
       -r <seconds>  output file rotation period (default: no rotation)
       -a            disable alignment of output file rotation to multiples of the rotation interval
       -l <filename> file to write the filename of the latest complete output file to
       -c <level>    output compression level to use (default: 6)
       -m <mode>     output mode: 'ascii' or 'binary' (default: binary)
...
```

Currently the following consumers are part of the official BGPView package:

### Utility Consumers

#### `archiver`

Serializes views to files (either in ASCII or compact binary format).

Usage:
```
consumer usage: archiver
       -f <filename> output file pattern for writing views
                       accepts same format parameters as strftime(3)
                       as well as '%s' to write unix time
       -r <seconds>  output file rotation period (default: no rotation)
       -a            disable alignment of output file rotation to multiples of the rotation interval
       -l <filename> file to write the filename of the latest complete output file to
       -c <level>    output compression level to use (default: 6)
       -m <mode>     output mode: 'ascii' or 'binary' (default: binary)
```

#### `view-sender`

Used in the realtime distributed system to publish views to Kafka.

Usage:
```
consumer usage: view-sender [options] -n <instance-name> -i <io-module>
       -i <module opts>      IO module to use for sending views.
                               Available modules:
                                - kafka
       -n <instance-name>    Unique name for this sender (required)
       -s <sync-interval>   Sync frame freq. in secs (default: 3600)
                               (used only for Kafka)
       -4 <pfx-cnt>          Only send peers with > N IPv4 pfxs (default: 400000)
       -6 <pfx-cnt>          Only send peers with > N IPv6 pfxs (default: 10000)
```

#### `visibility`

Calculates simple visibility information. Used by many other
consumers.

Usage:
```
consumer usage: visibility
       -4 <pfx-cnt>  # pfxs in a IPv4 full-feed table (default: 400000)
       -6 <pfx-cnt>  # pfxs in a IPv6 full-feed table (default: 10000)
       -m <mask-len> minimum mask length for pfxs (default: 6)
       -p <peer-cnt> # peers that must observe a pfx (default: 10)
```

### Prefix-Origin Consumers

#### `peer-pfx-origins`

"Cecilia's consumer". Generates "un-opinionated" per-peer
prefix-origin information.

Usage:
```
consumer usage: peer-pfx-origins
       -o <path>             output directory
       -c                    only output peer counts
```

#### `pfx2as`

Accumulates per-prefix origin information across many views and writes
summary information periodically. Used as input for the new high-level
CAIDA Prefix2AS dataset.

Usage:
```
consumer usage: pfx2as
       -i <interval>  output interval in seconds (default 86400)
       -o <path>      output directory
       -f <fmt>       output format: "dsv" (default) or "json"
       -c             output peer counts, not full list
       -v             split prefixes into files by IP version
```

### BGP Hijacks Observatory Consumers

#### `edges`

Monitors AS paths and detects new "edges" (AS links).

#### `moas`

Identifies multiple-origin prefixes.

#### `subpfx`

Identifies sub-prefix announcements.

#### `announced-pfxs`

Aggregates data across views and outputs information about announced
prefixes.

Usage:
```
consumer usage: announced-pfxs
       -w <window-size>      window size in seconds (default 604800)
       -i <output-interval>  output interval in seconds (default 86400)
       -o <path>             output folder (default: current folder)
```

#### `pfx-origins`

Tracks changes in prefix origin ASes between views.

Usage:
```
consumer usage: pfx-origins
       -o <path>             output folder (default: ./)
```

#### `routed-space`

Outputs information about address space that is "routed".

Usage:
```
consumer usage: routed-space
       -w <window-size>      window size in seconds (default 86400)
       -o <path>             output folder (default: current folder)
```

#### `triplets`

Output information about unique "triplets" seen in views.

Usage:
```
consumer usage: triplets
       -w <window-size>      window size in seconds (default 604800)
       -o <output-folder>    output folder (default: ./)
```

### IODA Consumers

#### `per-as-visibility`

Tracks per-AS statistics about prefixes announced on BGP.

Usage:
```
consumer usage: per-as-visibility
```

#### `per-geo-visibility`

Tracks per-geo statistics about prefixes announced on BGP.

Usage:
```
consumer usage: per-geo-visibility -p <ipmeta-provider>
```

### Test/Template Consumers

#### `test`

Simple testing consumer.

Usage:
```
consumer usage: test
```

#### `myviewprocess`

Template consumer that can be copied to start development of a new consumer.

### Misc Consumers
 - `pathchange`
 - `perfmonitor`


## Writing a New Consumer

TODO
